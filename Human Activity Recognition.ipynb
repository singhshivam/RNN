{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data was collected from 30 subjects aged between 19 and 48 years old performing one of six standard activities while wearing a waist-mounted smartphone that recorded the movement data. Video was recorded of each subject performing the activities and the movement data was labeled manually from these videos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The six activities performed were as follows:\n",
    "- Walking\n",
    "- Walking Upstairs\n",
    "- Walking Downstairs\n",
    "- Sitting\n",
    "- Standing\n",
    "- Laying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop an LSTM Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm model\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import to_categorical\n",
    "from matplotlib import pyplot\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a single file as a numpy array\n",
    "def load_file(filepath):\n",
    "    dataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
    "    return dataframe.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a list of files into a 3D array of [samples, timesteps, features]\n",
    "def load_group(filenames, prefix=''):\n",
    "    loaded = list()\n",
    "    for name in filenames:\n",
    "        data = load_file(prefix + name)\n",
    "        loaded.append(data)\n",
    "    # stack group so that features are the 3rd dimension\n",
    "    loaded = dstack(loaded)\n",
    "    return loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a dataset group, such as train or test\n",
    "def load_dataset_group(group, prefix=''):\n",
    "    filepath = prefix + group + '/Inertial Signals/'\n",
    "    # load all 9 files as a single array\n",
    "    filenames = list()\n",
    "    # total acceleration\n",
    "    filenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n",
    "    # body acceleration\n",
    "    filenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n",
    "    # body gyroscope\n",
    "    filenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n",
    "    # load input data\n",
    "    X = load_group(filenames, filepath)\n",
    "    # load class output\n",
    "    y = load_file(prefix + group + '/y_'+group+'.txt')\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output data is defined as an integer for the class number. We must one hot encode these class integers so that the data is suitable for fitting a neural network multi-class classification model. We can do this by calling the `to_categorical()` Keras function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset, returns train and test X and y elements\n",
    "def load_dataset(prefix=''):\n",
    "    # load all train\n",
    "    trainX, trainy = load_dataset_group('train', prefix + 'HARDataset/')\n",
    "    print(trainX.shape, trainy.shape)\n",
    "    # load all test\n",
    "    testX, testy = load_dataset_group('test', prefix + 'HARDataset/')\n",
    "    print(testX.shape, testy.shape)\n",
    "    # zero-offset class values\n",
    "    trainy = trainy - 1\n",
    "    testy = testy - 1\n",
    "    # one hot encode y\n",
    "    trainy = to_categorical(trainy)\n",
    "    testy = to_categorical(testy)\n",
    "    print(trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
    "    return trainX, trainy, testX, testy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit and Evaluate Model\n",
    "We define `evaluate_model()` that takes the `train` and `test` dataset. It will fil the `train` dataset and evaluate the results on `test` dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LSTM model requires a three-dimensional input with `[samples, time steps, features]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and evaluate a model\n",
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "    verbose, epochs, batch_size = 0, 15, 64\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, input_shape=(n_timesteps,n_features)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize scores\n",
    "def summarize_results(scores):\n",
    "    print(scores)\n",
    "    m, s = mean(scores), std(scores)\n",
    "    print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run an experiment\n",
    "def run_experiment(repeats=10):\n",
    "    # load data\n",
    "    trainX, trainy, testX, testy = load_dataset()\n",
    "    # repeat experiment\n",
    "    scores = list()\n",
    "    for r in range(repeats):\n",
    "        score = evaluate_model(trainX, trainy, testX, testy)\n",
    "        score = score * 100.0\n",
    "        print('>#%d: %.3f' % (r+1, score))\n",
    "        scores.append(score)\n",
    "    # summarize results\n",
    "    summarize_results(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 128, 9) (7352, 1)\n",
      "(2947, 128, 9) (2947, 1)\n",
      "(7352, 128, 9) (7352, 6) (2947, 128, 9) (2947, 6)\n",
      "WARNING:tensorflow:From /home/shivam/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      ">#1: 88.259\n"
     ]
    }
   ],
   "source": [
    "# run the experiment\n",
    "run_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deconstructing above code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindir = 'HARDataset/train/Inertial Signals/'\n",
    "\n",
    "trainfiles = ['total_acc_x_train.txt',\n",
    " 'total_acc_y_train.txt',\n",
    " 'total_acc_z_train.txt',\n",
    " 'body_acc_x_train.txt',\n",
    " 'body_acc_y_train.txt',\n",
    " 'body_acc_z_train.txt',\n",
    " 'body_gyro_x_train.txt',\n",
    " 'body_gyro_y_train.txt',\n",
    " 'body_gyro_z_train.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a single file as a numpy array\n",
    "def load_file(filepath):\n",
    "    dataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
    "    return dataframe.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7352, 128, 9)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded = list()\n",
    "for name in filenames:\n",
    "    data = load_file(traindir + name)\n",
    "    loaded.append(data)\n",
    "# stack group so that features are the 3rd dimension\n",
    "loaded = dstack(loaded)\n",
    "loaded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.012817</td>\n",
       "      <td>1.022833</td>\n",
       "      <td>1.022028</td>\n",
       "      <td>1.017877</td>\n",
       "      <td>1.023680</td>\n",
       "      <td>1.016974</td>\n",
       "      <td>1.017746</td>\n",
       "      <td>1.019263</td>\n",
       "      <td>1.016417</td>\n",
       "      <td>1.020745</td>\n",
       "      <td>...</td>\n",
       "      <td>1.020981</td>\n",
       "      <td>1.018065</td>\n",
       "      <td>1.019638</td>\n",
       "      <td>1.020017</td>\n",
       "      <td>1.018766</td>\n",
       "      <td>1.019815</td>\n",
       "      <td>1.019290</td>\n",
       "      <td>1.018445</td>\n",
       "      <td>1.019372</td>\n",
       "      <td>1.021171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.018851</td>\n",
       "      <td>1.022380</td>\n",
       "      <td>1.020781</td>\n",
       "      <td>1.020218</td>\n",
       "      <td>1.021344</td>\n",
       "      <td>1.020522</td>\n",
       "      <td>1.019790</td>\n",
       "      <td>1.019216</td>\n",
       "      <td>1.018307</td>\n",
       "      <td>1.017996</td>\n",
       "      <td>...</td>\n",
       "      <td>1.019291</td>\n",
       "      <td>1.019258</td>\n",
       "      <td>1.020736</td>\n",
       "      <td>1.020950</td>\n",
       "      <td>1.020491</td>\n",
       "      <td>1.018685</td>\n",
       "      <td>1.015660</td>\n",
       "      <td>1.014788</td>\n",
       "      <td>1.016499</td>\n",
       "      <td>1.017849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.023127</td>\n",
       "      <td>1.021882</td>\n",
       "      <td>1.019178</td>\n",
       "      <td>1.015861</td>\n",
       "      <td>1.012893</td>\n",
       "      <td>1.016451</td>\n",
       "      <td>1.020331</td>\n",
       "      <td>1.020266</td>\n",
       "      <td>1.021759</td>\n",
       "      <td>1.018649</td>\n",
       "      <td>...</td>\n",
       "      <td>1.020304</td>\n",
       "      <td>1.021516</td>\n",
       "      <td>1.019417</td>\n",
       "      <td>1.019312</td>\n",
       "      <td>1.019448</td>\n",
       "      <td>1.019434</td>\n",
       "      <td>1.019916</td>\n",
       "      <td>1.021041</td>\n",
       "      <td>1.022935</td>\n",
       "      <td>1.022019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.017682</td>\n",
       "      <td>1.018149</td>\n",
       "      <td>1.019854</td>\n",
       "      <td>1.019880</td>\n",
       "      <td>1.019121</td>\n",
       "      <td>1.020479</td>\n",
       "      <td>1.020595</td>\n",
       "      <td>1.016340</td>\n",
       "      <td>1.010611</td>\n",
       "      <td>1.009013</td>\n",
       "      <td>...</td>\n",
       "      <td>1.021295</td>\n",
       "      <td>1.022934</td>\n",
       "      <td>1.022183</td>\n",
       "      <td>1.021637</td>\n",
       "      <td>1.020598</td>\n",
       "      <td>1.018887</td>\n",
       "      <td>1.019161</td>\n",
       "      <td>1.019916</td>\n",
       "      <td>1.019602</td>\n",
       "      <td>1.020735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.019952</td>\n",
       "      <td>1.019616</td>\n",
       "      <td>1.020933</td>\n",
       "      <td>1.023061</td>\n",
       "      <td>1.022242</td>\n",
       "      <td>1.020867</td>\n",
       "      <td>1.021939</td>\n",
       "      <td>1.022300</td>\n",
       "      <td>1.022302</td>\n",
       "      <td>1.022254</td>\n",
       "      <td>...</td>\n",
       "      <td>1.022687</td>\n",
       "      <td>1.023670</td>\n",
       "      <td>1.019899</td>\n",
       "      <td>1.017381</td>\n",
       "      <td>1.020389</td>\n",
       "      <td>1.023884</td>\n",
       "      <td>1.021753</td>\n",
       "      <td>1.019425</td>\n",
       "      <td>1.018896</td>\n",
       "      <td>1.016787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  1.012817  1.022833  1.022028  1.017877  1.023680  1.016974  1.017746   \n",
       "1  1.018851  1.022380  1.020781  1.020218  1.021344  1.020522  1.019790   \n",
       "2  1.023127  1.021882  1.019178  1.015861  1.012893  1.016451  1.020331   \n",
       "3  1.017682  1.018149  1.019854  1.019880  1.019121  1.020479  1.020595   \n",
       "4  1.019952  1.019616  1.020933  1.023061  1.022242  1.020867  1.021939   \n",
       "\n",
       "        7         8         9    ...       118       119       120       121  \\\n",
       "0  1.019263  1.016417  1.020745  ...  1.020981  1.018065  1.019638  1.020017   \n",
       "1  1.019216  1.018307  1.017996  ...  1.019291  1.019258  1.020736  1.020950   \n",
       "2  1.020266  1.021759  1.018649  ...  1.020304  1.021516  1.019417  1.019312   \n",
       "3  1.016340  1.010611  1.009013  ...  1.021295  1.022934  1.022183  1.021637   \n",
       "4  1.022300  1.022302  1.022254  ...  1.022687  1.023670  1.019899  1.017381   \n",
       "\n",
       "        122       123       124       125       126       127  \n",
       "0  1.018766  1.019815  1.019290  1.018445  1.019372  1.021171  \n",
       "1  1.020491  1.018685  1.015660  1.014788  1.016499  1.017849  \n",
       "2  1.019448  1.019434  1.019916  1.021041  1.022935  1.022019  \n",
       "3  1.020598  1.018887  1.019161  1.019916  1.019602  1.020735  \n",
       "4  1.020389  1.023884  1.021753  1.019425  1.018896  1.016787  \n",
       "\n",
       "[5 rows x 128 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exploring single file\n",
    "df = read_csv(traindir + trainfiles[0], header=None, delim_whitespace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.012817 , 1.022833 , 1.022028 , ..., 1.018445 , 1.019372 ,\n",
       "        1.021171 ],\n",
       "       [1.018851 , 1.02238  , 1.020781 , ..., 1.014788 , 1.016499 ,\n",
       "        1.017849 ],\n",
       "       [1.023127 , 1.021882 , 1.019178 , ..., 1.021041 , 1.022935 ,\n",
       "        1.022019 ],\n",
       "       ...,\n",
       "       [0.7548917, 0.8043137, 0.831714 , ..., 0.6956257, 0.7479103,\n",
       "        0.776768 ],\n",
       "       [0.9279268, 0.9129872, 0.9246597, ..., 0.6753473, 0.6603377,\n",
       "        0.719353 ],\n",
       "       [0.7980909, 0.8192417, 0.8658821, ..., 0.8980947, 0.8283723,\n",
       "        0.8002428]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7352, 128)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
