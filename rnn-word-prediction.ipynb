{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/shivam/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/shivam/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/shivam/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/shivam/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/shivam/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/shivam/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/shivam/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/shivam/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/shivam/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/shivam/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/shivam/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/shivam/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       \" A \"\"Barometer\"\" Neuron enhances stability in...\n",
       "1       \" This invention is a novel high-speed neural ...\n",
       "2       An optical information processor for use as a ...\n",
       "3       A method and system for intelligent control of...\n",
       "4       A method and system for intelligent control of...\n",
       "                              ...                        \n",
       "4537    A neural network is disclosed in which communi...\n",
       "4538    [Object] An object is to provide an apparatus ...\n",
       "4539    An XML-based symbolic computer language, inter...\n",
       "4540    A convolution engine, such as a convolution ne...\n",
       "4541    This disclosure relates to improved sketch-bas...\n",
       "Name: patent_abstract, Length: 4542, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('patents.csv')\n",
    "abstracts = data['patent_abstract']\n",
    "abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Neural signal amplifiers include an operational amplifier and a feedback network coupled between an output and an input thereof. The feedback network includes a tunnel field effect transistor (“TFET”) pseudo resistor that exhibits bi-directional conductivity. A drain region of the TFET may be electr'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstracts[100][:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 35, 1689, 95, 11, 716, 1018, 4, 2, 303, 10, 292, 58, 11, 19]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer (num_words=None,\n",
    "                      filters='\"#$%&*+/:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                      lower=True, split=' ')\n",
    "\n",
    "# training tokenizer on abstracts would result in tokenizer\n",
    "# assigning distinct int value for each distinct word\n",
    "tokenizer.fit_on_texts(abstracts)\n",
    "sequences = tokenizer.texts_to_sequences(abstracts)\n",
    "sequences[100][:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neural signal amplifiers include an operational amplifier and a feedback network coupled between an output and an input thereof. the feedback network includes a tunnel field effect transistor (“tfet”) pseudo resistor that exhibits bi-directional conductivity. a drain region of the'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mapping indexes to words\n",
    "idx_word = tokenizer.index_word\n",
    "\n",
    "# converting tokenized list to string\n",
    "' '.join(idx_word[w] for w in sequences[100][:40])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Give the network a sequence of words and train it to predict the next word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i.e.  we give our network 50 words and train it to predict the 51st."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating features and labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the first 50 words as features with the 51st as the label, then use words 2–51 as features and predict the 52nd and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364883, 50)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = []\n",
    "labels = []\n",
    "\n",
    "training_length = 50\n",
    "\n",
    "for seq in sequences:\n",
    "    # create multiple training examples for each sequence\n",
    "    # range from 50 to length/end ofcurrent sequence\n",
    "    for i in range(training_length, len(seq)):\n",
    "        # extract features and label\n",
    "        extract = seq[i - training_length:i + 1]\n",
    "        \n",
    "        features.append(extract[:-1])\n",
    "        labels.append(extract[-1])\n",
    "\n",
    "features = np.array(features)\n",
    "\n",
    "# we have 364,883 sequences with 50 features each \n",
    "# (or each sequence has 50 timesteps)\n",
    "features.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "def create_train_valid(features,\n",
    "                       labels,\n",
    "                       num_words,\n",
    "                       train_fraction=0.7):\n",
    "    \"\"\"Create training and validation features and labels.\"\"\"\n",
    "\n",
    "    # Randomly shuffle features and labels\n",
    "    features, labels = shuffle(features, labels, random_state=50)\n",
    "\n",
    "    # Decide on number of samples for training\n",
    "    train_end = int(train_fraction * len(labels))\n",
    "\n",
    "    train_features = np.array(features[:train_end])\n",
    "    valid_features = np.array(features[train_end:])\n",
    "\n",
    "    train_labels = labels[:train_end]\n",
    "    valid_labels = labels[train_end:]\n",
    "\n",
    "    # Convert to arrays\n",
    "    X_train, X_valid = np.array(train_features), np.array(valid_features)\n",
    "\n",
    "    # Using int8 for memory savings\n",
    "    y_train = np.zeros((len(train_labels), num_words), dtype=np.int8)\n",
    "    y_valid = np.zeros((len(valid_labels), num_words), dtype=np.int8)\n",
    "\n",
    "    # One hot encoding of labels\n",
    "    for example_index, word_index in enumerate(train_labels):\n",
    "        y_train[example_index, word_index] = 1\n",
    "\n",
    "    for example_index, word_index in enumerate(valid_labels):\n",
    "        y_valid[example_index, word_index] = 1\n",
    "\n",
    "    # Memory management\n",
    "    import gc\n",
    "    gc.enable()\n",
    "    del features, labels, train_features, valid_features, train_labels, valid_labels\n",
    "    gc.collect()\n",
    "\n",
    "    return X_train, X_valid, y_train, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255418, 22026)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_words = len(idx_word) + 1\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = create_train_valid(\n",
    "    features, labels, num_words)\n",
    "X_train.shape\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do want to be careful about using up too much memory. One hot encoding the labels creates massive numpy arrays so I took care to delete the un-used objects from the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object: y_train   \tSize: 5.62583698 GB.\n",
      "Object: y_valid   \tSize: 2.411076202 GB.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "def check_sizes(gb_min=1):\n",
    "    for x in globals():\n",
    "        size = sys.getsizeof(eval(x)) / 1e9\n",
    "        if size > gb_min:\n",
    "            print(f'Object: {x:10}\\tSize: {size} GB.')\n",
    "\n",
    "\n",
    "check_sizes(gb_min=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
