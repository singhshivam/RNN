{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the data, split between train and test sets\n",
    "# x_train: feature matrix for 6000 images. Shape: (6000, 28, 28)\n",
    "# y_train: label array for 6000 images. Shape: (6000)\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "y_train[133]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow is channels_last\n",
    "# Keras refers to this as backend. We need not worry about it right now.\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    # this will get executed\n",
    "    # mnist.load_data() supplies the MNIST digits with structure (nb_samples, 28, 28)\n",
    "    # i.e. with 2 dimensions per example representing a greyscale image 28x28.\n",
    "    # The Convolution2D layers in Keras however, are designed to work with 3 dimensions per example.\n",
    "    # The greyscale image for MNIST digits input would either need a different CNN layer design \n",
    "    # (or a param to the layer constructor to accept a different shape), or the design could simply\n",
    "    # use a standard CNN and you must explicitly express the examples as 1-channel images. \n",
    "    # The Keras team chose the latter approach, which needs the re-shape.\n",
    "    # Learn more: \n",
    "    # https://datascience.stackexchange.com/questions/11704/reshaping-of-data-for-deep-learning-using-keras\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "    \n",
    "# NEW shape\n",
    "# x_train: (6000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Normalizing data: As expected, the pixel values range from 0 to 255\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "# np.utils.to_categorical is used to convert array of labeled data\n",
    "# (from 0 to nb_classes-1) to one-hot vector.\n",
    "# Arguments\n",
    "# y: class vector to be converted into a matrix\n",
    "# nb_classes: total number of classes\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# NEW shape:\n",
    "# y_train: (6000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/shivam/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/shivam/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 105s 2ms/step - loss: 0.2570 - accuracy: 0.9203 - val_loss: 0.0638 - val_accuracy: 0.9802\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 120s 2ms/step - loss: 0.0899 - accuracy: 0.9730 - val_loss: 0.0502 - val_accuracy: 0.9820\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 104s 2ms/step - loss: 0.0672 - accuracy: 0.9800 - val_loss: 0.0337 - val_accuracy: 0.9888\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 110s 2ms/step - loss: 0.0548 - accuracy: 0.9834 - val_loss: 0.0318 - val_accuracy: 0.9899\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 96s 2ms/step - loss: 0.0475 - accuracy: 0.9856 - val_loss: 0.0316 - val_accuracy: 0.9893\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 120s 2ms/step - loss: 0.0420 - accuracy: 0.9872 - val_loss: 0.0284 - val_accuracy: 0.9909\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 108s 2ms/step - loss: 0.0380 - accuracy: 0.9884 - val_loss: 0.0292 - val_accuracy: 0.9899\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 99s 2ms/step - loss: 0.0344 - accuracy: 0.9892 - val_loss: 0.0304 - val_accuracy: 0.9908\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 97s 2ms/step - loss: 0.0300 - accuracy: 0.9908 - val_loss: 0.0294 - val_accuracy: 0.9903\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 95s 2ms/step - loss: 0.0273 - accuracy: 0.9917 - val_loss: 0.0265 - val_accuracy: 0.9918\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 99s 2ms/step - loss: 0.0269 - accuracy: 0.9919 - val_loss: 0.0270 - val_accuracy: 0.9915\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 93s 2ms/step - loss: 0.0268 - accuracy: 0.9916 - val_loss: 0.0241 - val_accuracy: 0.9921\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f64bc05f8d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.02408905099705862\n",
      "Test accuracy: 0.9921000003814697\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
